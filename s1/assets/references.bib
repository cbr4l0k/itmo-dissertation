
@misc{pei_deepfake_2024,
	title = {Deepfake Generation and Detection: A Benchmark and Survey},
	url = {http://arxiv.org/abs/2403.17881},
	doi = {10.48550/arXiv.2403.17881},
	shorttitle = {Deepfake Generation and Detection},
	abstract = {Deepfake is a technology dedicated to creating highly realistic facial images and videos under specific conditions, which has significant application potential in fields such as entertainment, movie production, digital human creation, to name a few. With the advancements in deep learning, techniques primarily represented by Variational Autoencoders and Generative Adversarial Networks have achieved impressive generation results. More recently, the emergence of diffusion models with powerful generation capabilities has sparked a renewed wave of research. In addition to deepfake generation, corresponding detection technologies continuously evolve to regulate the potential misuse of deepfakes, such as for privacy invasion and phishing attacks. This survey comprehensively reviews the latest developments in deepfake generation and detection, summarizing and analyzing current state-of-the-arts in this rapidly evolving field. We first unify task definitions, comprehensively introduce datasets and metrics, and discuss developing technologies. Then, we discuss the development of several related sub-fields and focus on researching four representative deepfake fields: face swapping, face reenactment, talking face generation, and facial attribute editing, as well as forgery detection. Subsequently, we comprehensively benchmark representative methods on popular datasets for each field, fully evaluating the latest and influential published works. Finally, we analyze challenges and future research directions of the discussed fields.},
	number = {{arXiv}:2403.17881},
	author = {Pei, Gan and Zhang, Jiangning and Hu, Menghan and Zhang, Zhenyu and Wang, Chengjie and Wu, Yunsheng and Zhai, Guangtao and Yang, Jian and Shen, Chunhua and Tao, Dacheng},
	urldate = {2026-01-22},
	date = {2024-05-16},
	eprinttype = {arxiv},
	eprint = {2403.17881 [cs]},
	file = {Pei et al. - 2024 - Deepfake Generation and Detection A Benchmark and Survey.pdf:/home/cbr4l0k/Zotero/storage/6HNLK7I7/Pei et al. - 2024 - Deepfake Generation and Detection A Benchmark and Survey.pdf:application/pdf},
}

@article{melnik_face_2024,
	title = {Face Generation and Editing with {StyleGAN}: A Survey},
	volume = {46},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {http://arxiv.org/abs/2212.09102},
	doi = {10.1109/TPAMI.2024.3350004},
	shorttitle = {Face Generation and Editing with {StyleGAN}},
	abstract = {Our goal with this survey is to provide an overview of the state of the art deep learning methods for face generation and editing using {StyleGAN}. The survey covers the evolution of {StyleGAN}, from {PGGAN} to {StyleGAN}3, and explores relevant topics such as suitable metrics for training, different latent representations, {GAN} inversion to latent spaces of {StyleGAN}, face image editing, cross-domain face stylization, face restoration, and even Deepfake applications. We aim to provide an entry point into the field for readers that have basic knowledge about the field of deep learning and are looking for an accessible introduction and overview.},
	pages = {3557--3576},
	number = {5},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Melnik, Andrew and Miasayedzenkau, Maksim and Makarovets, Dzianis and Pirshtuk, Dzianis and Akbulut, Eren and Holzmann, Dennis and Renusch, Tarek and Reichert, Gustav and Ritter, Helge},
	urldate = {2026-01-22},
	date = {2024-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2212.09102 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/cbr4l0k/Zotero/storage/U2IW4IVN/Melnik et al. - 2024 - Face Generation and Editing with StyleGAN A Survey.pdf:application/pdf},
}

@inproceedings{nguyen_videofact_2024,
	location = {Waikoloa, {HI}, {USA}},
	title = {{VideoFACT}: Detecting Video Forgeries Using Attention, Scene Context, and Forensic Traces},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-1892-0},
	url = {https://ieeexplore.ieee.org/document/10483886/},
	doi = {10.1109/WACV57701.2024.00837},
	shorttitle = {{VideoFACT}},
	eventtitle = {2024 {IEEE}/{CVF} Winter Conference on Applications of Computer Vision ({WACV})},
	pages = {8548--8558},
	booktitle = {2024 {IEEE}/{CVF} Winter Conference on Applications of Computer Vision ({WACV})},
	publisher = {{IEEE}},
	author = {Nguyen, Tai D. and Fang, Shengbang and Stamm, Matthew C.},
	urldate = {2026-01-23},
	date = {2024-01-03},
	langid = {english},
	file = {PDF:/home/cbr4l0k/Zotero/storage/B3D2TYGL/Nguyen et al. - 2024 - VideoFACT Detecting Video Forgeries Using Attention, Scene Context, and Forensic Traces.pdf:application/pdf},
}

@misc{chang_how_2025,
	title = {How Far are {AI}-generated Videos from Simulating the 3D Visual World: A Learned 3D Evaluation Approach},
	url = {http://arxiv.org/abs/2406.19568},
	doi = {10.48550/arXiv.2406.19568},
	shorttitle = {How Far are {AI}-generated Videos from Simulating the 3D Visual World},
	abstract = {Recent advancements in video diffusion models enable the generation of photorealistic videos with impressive 3D consistency and temporal coherence. However, the extent to which these {AI}-generated videos simulate the 3D visual world remains underexplored. In this paper, we introduce Learned 3D Evaluation (L3DE), an objective, quantifiable, and interpretable method for assessing {AI}-generated videos' ability to simulate the real world in terms of 3D visual qualities and consistencies, without requiring manually labeled defects or quality annotations. Instead of relying on 3D reconstruction, which is prone to failure with in-the-wild videos, L3DE employs a 3D convolutional network, trained on monocular 3D cues of motion, depth, and appearance, to distinguish real from synthetic videos. Confidence scores from L3DE quantify the gap between real and synthetic videos in terms of 3D visual coherence, while a gradient-based visualization pinpoints unrealistic regions, improving interpretability. We validate L3DE through extensive experiments, demonstrating strong alignment with 3D reconstruction quality and human judgments. Our evaluations on leading generative models (e.g., Kling, Sora, and {MiniMax}) reveal persistent simulation gaps and subtle inconsistencies. Beyond generative video assessment, L3DE extends to broader applications: benchmarking video generation models, serving as a deepfake detector, and enhancing video synthesis by inpainting flagged inconsistencies. Project page: https://justin-crchang.github.io/l3de-project-page/},
	number = {{arXiv}:2406.19568},
	publisher = {{arXiv}},
	author = {Chang, Chirui and Liu, Jiahui and Liu, Zhengzhe and Lyu, Xiaoyang and Huang, Yi-Hua and Tao, Xin and Wan, Pengfei and Zhang, Di and Qi, Xiaojuan},
	urldate = {2026-01-23},
	date = {2025-10-05},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2406.19568 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/cbr4l0k/Zotero/storage/HX2ND4WJ/Chang et al. - 2025 - How Far are AI-generated Videos from Simulating the 3D Visual World A Learned 3D Evaluation Approac.pdf:application/pdf},
}

@misc{song_learning_2025,
	title = {On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection},
	url = {http://arxiv.org/abs/2410.23623},
	doi = {10.48550/arXiv.2410.23623},
	abstract = {Large numbers of synthesized videos from diffusion models pose threats to information security and authenticity, leading to an increasing demand for generated content detection. However, existing video-level detection algorithms primarily focus on detecting facial forgeries and often fail to identify diffusion-generated content with a diverse range of semantics. To advance the field of video forensics, we propose an innovative algorithm named Multi-Modal Detection({MM}-Det) for detecting diffusion-generated videos. {MM}-Det utilizes the profound perceptual and comprehensive abilities of Large Multi-modal Models ({LMMs}) by generating a Multi-Modal Forgery Representation ({MMFR}) from {LMM}’s multi-modal space, enhancing its ability to detect unseen forgery content. Besides, {MM}-Det leverages an In-and-Across Frame Attention ({IAFA}) mechanism for feature augmentation in the spatio-temporal domain. A dynamic fusion strategy helps refine forgery representations for the fusion. Moreover, we construct a comprehensive diffusion video dataset, called Diffusion Video Forensics ({DVF}), across a wide range of forgery videos. {MM}-Det achieves state-of-the-art performance in {DVF}, demonstrating the effectiveness of our algorithm. Both source code and {DVF} are available at link.},
	number = {{arXiv}:2410.23623},
	publisher = {{arXiv}},
	author = {Song, Xiufeng and Guo, Xiao and Zhang, Jiache and Li, Qirui and Bai, Lei and Liu, Xiaoming and Zhai, Guangtao and Liu, Xiaohong},
	urldate = {2026-01-23},
	date = {2025-06-19},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2410.23623 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/cbr4l0k/Zotero/storage/TL9TA4CZ/Song et al. - 2025 - On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection.pdf:application/pdf},
}

@article{ali_interframe_2025,
	title = {Interframe Forgery Video Detection: Datasets, Methods, Challenges, and Search Directions},
	volume = {14},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/14/13/2680},
	doi = {10.3390/electronics14132680},
	shorttitle = {Interframe Forgery Video Detection},
	abstract = {The authenticity of digital video content has become a critical issue in multimedia security due to the significant rise in video editing and manipulation in recent years. The detection of interframe forgeries is essential for identifying manipulations, including frame duplication, deletion, and insertion. These are popular techniques for altering video footage without leaving visible visual evidence. This study provides a detailed review of various methods for detecting video forgery, with a primary focus on interframe forgery techniques. The article evaluates approaches by assessing key performance measures. According to a statistical overview, machine learning has traditionally been used more frequently, but deep learning techniques are gaining popularity due to their outstanding performance in handling complex tasks and robust post-processing capabilities. The study highlights the significance of interframe forgery detection for forensic analysis, surveillance, and content moderation, as demonstrated through both evaluation and case studies. It aims to summarize existing studies and identify limitations to guide future research towards more robust, scalable, and generalizable methods, such as the development of benchmark datasets that reflect real-world video manipulation diversity. This emphasizes the necessity of creating large public datasets of manipulated high-resolution videos to support reliable integrity evaluations in dealing with widespread media manipulation.},
	pages = {2680},
	number = {13},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Ali, Mona M. and Ghali, Neveen I. and Hamza, Hanaa M. and Hosny, Khalid M. and Vrochidou, Eleni and Papakostas, George A.},
	urldate = {2026-01-23},
	date = {2025-07-02},
	langid = {english},
	file = {PDF:/home/cbr4l0k/Zotero/storage/4REBJBF6/Ali et al. - 2025 - Interframe Forgery Video Detection Datasets, Methods, Challenges, and Search Directions.pdf:application/pdf},
}

@article{zhou_deep_2021,
  title={Deep Video Inpainting Detection},
  author={Zhou, Peng and Yu, Ning and Wu, Zuxuan and Davis, Larry S and Shrivastava, Abhinav and Lim, Ser Nam},
  booktitle = {BMVC},
  year={2021}
}

@article{diwan_systematic_2024,
	title = {Systematic analysis of video tampering and detection techniques},
	volume = {11},
	issn = {2331-1916},
	url = {https://www.tandfonline.com/doi/full/10.1080/23311916.2024.2424466},
	doi = {10.1080/23311916.2024.2424466},
	pages = {2424466},
	number = {1},
	journaltitle = {Cogent Engineering},
	shortjournal = {Cogent Engineering},
	author = {Diwan, Anjali and Dixit, Saurav and Subbiah, Ram and Mahadeva, Rajesh},
	urldate = {2026-01-23},
	date = {2024-12-31},
	langid = {english},
	file = {Full Text PDF:/home/cbr4l0k/Zotero/storage/MW3JBFEP/Diwan et al. - 2024 - Systematic analysis of video tampering and detection techniques.pdf:application/pdf},
}

@article{barglazan_image_2024,
	title = {Image Inpainting Forgery Detection: A Review},
	volume = {10},
	issn = {2313-433X},
	url = {https://www.mdpi.com/2313-433X/10/2/42},
	doi = {10.3390/jimaging10020042},
	shorttitle = {Image Inpainting Forgery Detection},
	abstract = {In recent years, significant advancements in the field of machine learning have influenced the domain of image restoration. While these technological advancements present prospects for improving the quality of images, they also present difficulties, particularly the proliferation of manipulated or counterfeit multimedia information on the internet. The objective of this paper is to provide a comprehensive review of existing inpainting algorithms and forgery detections, with a specific emphasis on techniques that are designed for the purpose of removing objects from digital images. In this study, we will examine various techniques encompassing conventional texture synthesis methods as well as those based on neural networks. Furthermore, we will present the artifacts frequently introduced by the inpainting procedure and assess the state-of-the-art technology for detecting such modifications. Lastly, we shall look at the available datasets and how the methods compare with each other. Having covered all the above, the outcome of this study is to provide a comprehensive perspective on the abilities and constraints of detecting object removal via the inpainting procedure in images.},
	pages = {42},
	number = {2},
	journaltitle = {Journal of Imaging},
	shortjournal = {J. Imaging},
	author = {Barglazan, Adrian-Alin and Brad, Remus and Constantinescu, Constantin},
	urldate = {2026-01-23},
	date = {2024-02-02},
	langid = {english},
	file = {Full Text:/home/cbr4l0k/Zotero/storage/NYBM9W6I/Barglazan et al. - 2024 - Image Inpainting Forgery Detection A Review.pdf:application/pdf},
}

@article{layton_sok_nodate,
	title = {{SoK}: The Good, The Bad, and The Unbalanced: Measuring Structural Limitations of Deepfake Media Datasets},
	abstract = {Deepfake media represents an important and growing threat not only to computing systems but to society at large. Datasets of image, video, and voice deepfakes are being created to assist researchers in building strong defenses against these emerging threats. However, despite the growing number of datasets and the relative diversity of their samples, little guidance exists to help researchers select datasets and then meaningfully contrast their results against prior eﬀorts. To assist in this process, this paper presents the ﬁrst systematization of deepfake media. Using traditional anomaly detection datasets as a baseline, we characterize the metrics, generation techniques, and class distributions of existing datasets. Through this process, we discover signiﬁcant problems impacting the comparability of systems using these datasets, including unaccounted-for heavy class imbalance and reliance upon limited metrics. These observations have a potentially profound impact should such systems be transitioned to practice - as an example, we demonstrate that the widely-viewed best detector applied to a typical call center scenario would result in only 1 out of 333 ﬂagged results being a true positive. To improve reproducibility and future comparisons, we provide a template for reporting results in this space and advocate for the release of model score ﬁles such that a wider range of statistics can easily be found and/or calculated. Through this, and our recommendations for improving dataset construction, we provide important steps to move this community forward.},
	author = {Layton, Seth and Tucker, Tyler and Olszewski, Daniel and Warren, Kevin and Butler, Kevin and Traynor, Patrick},
	langid = {english},
	file = {PDF:/home/cbr4l0k/Zotero/storage/XUWJEK2S/Layton et al. - SoK The Good, The Bad, and The Unbalanced Measuring Structural Limitations of Deepfake Media Datas.pdf:application/pdf},
}

@article{somoray_human_2025,
	title = {Human Performance in Deepfake Detection: A Systematic Review},
	volume = {2025},
	issn = {2578-1863, 2578-1863},
	url = {https://onlinelibrary.wiley.com/doi/10.1155/hbe2/1833228},
	doi = {10.1155/hbe2/1833228},
	shorttitle = {Human Performance in Deepfake Detection},
	abstract = {Deepfakes
              refer to a wide range of computer‐generated synthetic media, in which a person’s appearance or likeness is altered to resemble that of another. This systematic review is aimed at providing an overview of the existing research into people’s ability to detect deepfakes. Five databases ({IEEE}, {ProQuest}, {PubMed}, Web of Science, and Scopus) were searched up to December 2023. Studies were included if they (1) were an original study; (2) were reported in English; (3) examined people’s detection of deepfakes; (4) examined the influence of an intervention, strategy, or variable on deepfake detection; and (5) reported relevant data needed to evaluate detection accuracy. Forty independent studies from 30 unique records were included in the review. Results were narratively summarized, with key findings organized based on the review’s research questions. Studies used different performance measures, making it difficult to compare results across the literature. Detection accuracy varies widely, with some studies showing humans outperforming {AI} models and others indicating the opposite. Detection performance is also influenced by person‐level (e.g., cognitive ability, analytical thinking) and stimuli‐level factors (e.g., quality of deepfake, familiarity with the subject). Interventions to improve people’s deepfake detection yielded mixed results. Humans and {AI}‐based detection models focus on different aspects when detecting, suggesting a potential for human–{AI} collaboration. The findings highlight the complex interplay of factors influencing human deepfake detection and the need for further research to develop effective strategies for deepfake detection.},
	pages = {1833228},
	number = {1},
	journaltitle = {Human Behavior and Emerging Technologies},
	shortjournal = {Human Behavior and Emerging Technologies},
	author = {Somoray, Klaire and Miller, Dan J. and Holmes, Mary},
	editor = {Bhandari, Rudra},
	urldate = {2026-01-23},
	date = {2025-01},
	langid = {english},
	file = {PDF:/home/cbr4l0k/Zotero/storage/CTFGLA4E/Somoray et al. - 2025 - Human Performance in Deepfake Detection A Systematic Review.pdf:application/pdf},
}

@misc{ma_your_2026,
	title = {Your One-Stop Solution for {AI}-Generated Video Detection},
	url = {http://arxiv.org/abs/2601.11035},
	doi = {10.48550/arXiv.2601.11035},
	abstract = {Recent advances in generative modeling can create remarkably realistic synthetic videos, making it increasingly difficult for humans to distinguish them from real ones and necessitating reliable detection methods. However, two key limitations hinder the development of this field. {\textbackslash}textbf\{From the dataset perspective\}, existing datasets are often limited in scale and constructed using outdated or narrowly scoped generative models, making it difficult to capture the diversity and rapid evolution of modern generative techniques. Moreover, the dataset construction process frequently prioritizes quantity over quality, neglecting essential aspects such as semantic diversity, scenario coverage, and technological representativeness. {\textbackslash}textbf\{From the benchmark perspective\}, current benchmarks largely remain at the stage of dataset creation, leaving many fundamental issues and in-depth analysis yet to be systematically explored. Addressing this gap, we propose {AIGVDBench}, a benchmark designed to be comprehensive and representative, covering {\textbackslash}textbf\{31\} state-of-the-art generation models and over {\textbackslash}textbf\{440,000\} videos. By executing more than {\textbackslash}textbf\{1,500\} evaluations on {\textbackslash}textbf\{33\} existing detectors belonging to four distinct categories. This work presents {\textbackslash}textbf\{8 in-depth analyses\} from multiple perspectives and identifies {\textbackslash}textbf\{4 novel findings\} that offer valuable insights for future research. We hope this work provides a solid foundation for advancing the field of {AI}-generated video detection. Our benchmark is open-sourced at https://github.com/{LongMa}-2025/{AIGVDBench}.},
	number = {{arXiv}:2601.11035},
	publisher = {{arXiv}},
	author = {Ma, Long and Xue, Zihao and Wang, Yan and Yan, Zhiyuan and Xu, Jin and Jiang, Xiaorui and Yu, Haiyang and Liao, Yong and Bi, Zhen},
	urldate = {2026-01-23},
	date = {2026-01-16},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2601.11035 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:/home/cbr4l0k/Zotero/storage/6YGAIT5G/Ma et al. - 2026 - Your One-Stop Solution for AI-Generated Video Detection.pdf:application/pdf},
}
